# รายงานสรุปการดำเนินการข้อสอบ Proof of Concept (POC) ตำแหน่ง นักวิทยาศาสตร์ข้อมูล
**รหัสผู้เข้าสอบ : PSU-057870 นายไตรรัตน์ อารมฤทธิ์**


## รายละเอียดของรายงาน
รายงานประกอบด้วยข้อมูลทั้งหมด 2 ส่วน ดังนี้
 - **ส่วนที่ 1** : การวิเคราะห์ภูมิทัศน์งานวิจัยเชิงเปรียบเทียบของการแข่งขันด้านงานวิจัยของมหาวิทยาลัยชั้นนำในประเทศไทย
 - **ส่วนที่ 2** : การพัฒนาแบบจำลอง (Model) เพื่อทำนาย "ศักยภาพในการสร้างผลกระทบของบทความวิจัย" 

###  1. การวิเคราะห์ภูมิทัศน์งานวิจัยเชิงเปรียบเทียบของการแข่งขันด้านงานวิจัยของมหาวิทยาลัยชั้นนำในประเทศไทย

ขั้นตอนดำเนินการ ดังนี้

 1. ทำการศึกษารายละเอียดโครงสร้าง Metadata จากข้อมูลบนฐาน ArXiv ซึ่งมีรายละเอียดของผลงานวิจัยที่ใช้สำหรับการดำเนินการ
 2. ระบุปัญหาที่พบในการศึกษาโครงสร้าง Metadata จากข้อมูลบนฐาน ArXiv 
	> **ปัญหาที่พบ :** การขาดข้อมูลที่เกี่ยวข้องกับผู้แต่งบทความ (Author) ซึ่งเป็นสิ่งที่สำคัญต่อการระบุ **หน่วยงานที่เกี่ยวข้องกับบทความวิจัย** และ **การอ้างอิงบทความวิจัย**ซึ่งจำเป็นต้องใช้ในการวิเคราะห์ครั้งนี้ 
	
	**วิธีแก้ไขปัญหาที่ได้ทดลอง**
	1.	**การดึงข้อมูลจากไฟล์ PDF** ที่มีอยู่บนฐาน ด้วยการทำ OCR ผ่าน Large Language Model (LLM) เนื่องจากบนความมีรูปแบบการเขียนที่แตกต่างกัน การใช้ LLM จึงมีประโยชน์ในการรับมือความแตกต่างที่เกิดขึ้น 
	2. **การดึงข้อมูลจาก third-party Databased  (OpenAlex)** เนื่องจากเป็นฐานข้อมูลที่มีความร่วมมือกับ Cornell university ที่เป็นผู้ดูแลฐานข้อมูล ArXiv และเมื่อเช็คจำนวนบทความที่อยู่บนฐานทั้งคู่นั้นมีปริมาณที่ใกล้เคียงกัน และนอกจากนั้นยังมีข้อมูลอ้างอิงบทความวิจัย ซึ่งจำเป็นต่อการวิเคราะห์ข้อมูลในส่วนที่ 2
	
	ดังนั้น จากกระบวนการทั้ง 2 ทางผู้สอบได้เลือก **ใช้วิธีการดึงข้อมูลจาก OpenAlex** เนื่องจากระยะเวลาที่กำหนดค่อนข้างสั้น ทำให้การดำเนินการ OCR จากบทความทั้งหมด ถึงแม้จะกรองให้เหลือตามที่โจทย์กำหนดแล้วก็ตาม

3. **กระบวนการดึงข้อมูลผ่าน API ของฐานข้อมูล OpenAlex** ทางผู้สอบได้ดำเนินการดึงข้อมูลโดยการเลือกบทความบนฐาน ArXiv ผ่าน Source และ กำหนดให้ดึงข้อมูลของกลุ่มประเทศเอเชียตะวันออกเฉียงใต้ (ASEAN)  โดยทำการตรวจสอบความครบถ้วนดังนี้
```mermaid
graph LR
A((ASEAN: 7,418))
A --> B((THAI: 422))
B --> C((G1: 281))
```
ซึ่งจำนวนดังกล่าวเป็นจำนวนที่ถูกต้องเมื่อเราทำการสืบค้นข้อมูลโดยใช้เงื่อนไข Source ร่วมกับ Institution ID ดังนั้น ทางผู้สอบจึงทำการดึงข้อมูลจากฐาน OpenAlex ทั้งหมด 7418 ผลงาน และ ทำการ Merge กับชุดข้อมูลตามที่โจทย์กำหนด `arxiv-metadata-oai-snapshot.json` ผ่าน work_id หรือเลขประจำบทความบนฐาน ArXiv

 4. **กระบวนการออกแบบโครงสร้างข้อมูล (DataModel)** โดยในการสอบครั้งนี้ทางผู้เข้าสอบได้มีการแบ่งข้อมูลออกเป็น 2 รูปแบบโครงสร้างข้อมูล คือ 
	1. ข้อมูลที่เน้นเฉพาะข้อมูลที่เกี่ยวข้องกับบทความเท่านั้น (Article_DB)
	2. ข้อมูลที่เน้นเชื่อมโยงข้อมูลที่เกี่ยวข้องกับผู้แต่งบทความ (Author_DB) 

ซึ่งทั้ง 2 โครงสร้างข้อมูลจะถูกนำไปใช้ในการวิเคราะห์ภูมิทัศน์งานวิจัยเชิงเปรียบเทียบของการแข่งขันด้านงานวิจัยของมหาวิทยาลัยชั้นนำในประเทศไทย ดังนี้
	 
 ### โจทย์วิเคราะห์ที่ 1 : เปรียบเทียบจำนวนผลงานตีพิมพ์ในแต่ละปีของมหาวิทยาลัยกลุ่มที่ 1 กลุ่มพัฒนาการวิจัยระดับแนวหน้าของโลก

 1. จากการดึงข้อมูลทั้งหมด พบว่า มหาวิทยาลัยกลุ่มที่ 1 ทั้ง 17 มหาวิทยาลัย ล้วนมีการตีพิมพ์ผลงานวิจัยในฐานข้อมูลทั้งสิ้น แต่เนื่องจากบางมหาวิทยาลัยมีจำนวนที่น้อยทำให้การวิเคราะห์ไม่สามารถให้ผลลัพธ์ที่ชัดเจน ดังนั้น ผู้สอบจึงทำการคัดเลือกมหาวิทยาลัยจำนวน 5 แห่ง ประกอบด้วย `จุฬาลงกรณ์มหาวิทยาลัย` `มหาวิทยาลัยมหิดล` `มหาวิทยาลัยสงขลานครินทร์` `มหาวิทยาลัยเทคโนโลยีพระจอมเกล้าธนบุรี` และ `มหาวิทยาลัยเชียงใหม่` ซึ่งทางผู้สอบได้ดำเนินการสร้าง Visulization ในรูปแบบของ GroupBar Chart และ Faceted Bar chart เพื่อแสดงข้อมูลเปรียบเทียบของทั้ง 5 มหาวิทยาลัยในแต่ละปีที่มีการตีพิมพ์ ดังภาพที่ 1-2
<img width="1117" height="627" alt="image" src="https://github.com/user-attachments/assets/a8b3fb0b-ee0f-4a3a-ad1f-5d7e10178228" />
<img width="1127" height="608" alt="image" src="https://github.com/user-attachments/assets/3694bec7-cfbf-45f5-9ff3-668967f281bd" />

**ข้อมูลเชิงลึก (Insight) :** จากกราฟภาพรวมชี้ให้เห็นว่าผลงานตีพิมพ์ของกลุ่มมหาวิทยาลัยวิจัยชั้นนำมีความ **"ผันผวนสูง"** และ **"ไม่มีผู้นำที่ครองตลาดอย่างถาวร"** แต่ละมหาวิทยาลัยมีความโดดเด่นขึ้นมาเป็นช่วงๆ สะท้อนให้เห็นถึงความสำเร็จของโครงการวิจัยเฉพาะทางหรือเป็นรอบๆ มากกว่าการเติบโตอย่างต่อเนื่องและยั่งยืน กลยุทธ์ในอนาคตจึงควรพิจารณาแนวทางสร้างความสม่ำเสมอและต่อยอดจากความสำเร็จที่เกิดขึ้นเป็นครั้งคราว แต่ในมุมมองของมหาวิทยาลัยสงขลานครินทร์ ถือว่า ยังมีงานวิจัยในฐาน ArXiv ที่น้อย ซึ่งถือเป็นเรื่องสามารถเข้าใจได้ว่านักวิจัยอาจจะมุ่งเน้นในการตีพิมพ์ผลงานบนฐานข้อมูล Scopus และ Web of Science ที่มีการจัดอันดับ และได้รับการยอมรับของทีมบริหารของมหาวิทยาลัยมากกว่า

 ### โจทย์วิเคราะห์ที่ 2 : วิเคราะห์และแสดงภาพเปรียบเทียบหมวดหมู่งานวิจัย (Categories) ที่แต่ละมหาวิทยาลัยให้ความสำคัญ
<img width="1110" height="581" alt="image" src="https://github.com/user-attachments/assets/8d8e6bc4-53f8-419f-b556-ba426a57b7c8" />

**ข้อมูลเชิงลึก (Insight) :** จากกราฟแสดงให้เห็น **อัตลักษณ์และความเชี่ยวชาญ** ที่แตกต่างกันอย่างชัดเจนของแต่ละมหาวิทยาลัย เราสามารถแบ่งมหาวิทยาลัยออกเป็น 2 กลุ่มหลัก คือ **กลุ่มเชี่ยวชาญเฉพาะทาง (Specialists)** ที่มีความเป็นเลิศในสาขาใดสาขาหนึ่งอย่างเด่นชัด และ **กลุ่มครอบคลุมหลากหลาย (Comprehensive)** ที่มีผลงานวิจัยในวงกว้าง แต่โดยรวมแล้วเราจะเห็นได้ว่าสาขาวิชาที่มักได้รับการตีพิมพ์บนฐาน ArXiv จะเป็นสาขาที่มีการเปลี่ยนแปลงขององค์ความรู้ที่รวดเร็ว มีการแข่งขันสูง และ มีความต้องการที่จะแลกเปลี่ยนข้อค้นพบที่รวดเร็วเพียงพอ เช่น สาขาวิทยาการคอมพิวเตอร์ (Computer Science) , สาขาฟิสิกส์และดาราศาสตร์ เป็นต้น

นอกจากการวิเคราะห์หมวดหมู่งานวิจัย หรือ สาขาวิชา (Subject Area) ทางผู้สอบได้ดำเนินการประยุกต์ใช้หลักการทางด้านเศรษฐศาสตร์ คือ `Economic Complexity Index` หรือ `ดัชนีความซับซ้อนทางเศรษฐกิจ (ECI)` เข้ามาประยุกต์ใช้ในการวิเคราะห์ข้อมูลเชิงลึกของมหาวิทยาลัย และ หัวข้อวิจัยที่มีความเชี่ยวชาญของแต่ละมหาวิทยาลัย โดยรายละเอียดมีดังนี้


# **Economic Complexity Index (Research) Analysis**

## **คำจำกัดความ (Definition)**

> **ดัชนีความซับซ้อนทางเศรษฐกิจ (Economic Complexity Index: ECI)**  
> ในบริบทของการวิจัย เป็นตัวชี้วัดที่ใช้ประเมิน **ขีดความสามารถและความซับซ้อนของสถาบันวิจัย**  
> โดยอาศัยแนวคิดจากดัชนีความซับซ้อนทางเศรษฐกิจในภาคการค้า มาประยุกต์ใช้กับผลงานวิจัย

โดยหลักการ ECI ประกอบด้วย:
1. **ความหลากหลาย (Diversity):** จำนวนหัวข้องานวิจัยที่สถาบันมีผลงานตีพิมพ์  
2. **ความแพร่หลาย (Ubiquity):** ระดับความเฉพาะทางหรือความหายากของแต่ละหัวข้อเมื่อเทียบกับสถาบันอื่น  

สถาบันที่มีการตีพิมพ์ในหัวข้อที่มีความเฉพาะทางสูงและหลากหลาย  
จะมีค่า **ECI สูงกว่า** ซึ่งสะท้อนถึงความสามารถในการทำวิจัยที่ซับซ้อนและมีคุณภาพสูง  

---

## **การตีความ (Interpretation)**

- **ค่า ECI สูง:**  
  - สะท้อนว่าสถาบันมีความสามารถในการทำวิจัยใน **หัวข้อที่หลากหลายและเฉพาะทางสูง**  
  - บ่งชี้ถึงศักยภาพในการผลิตผลงานวิจัยที่ **ซับซ้อนและมีผลกระทบสูง**  
  - *ตัวอย่าง:* มหาวิทยาลัยที่มีผลงานในด้าน AI เชิงลึก ควอนตัมคอมพิวติ้ง และวัสดุศาสตร์ขั้นสูง จะมีค่า ECI สูง  

- **ค่า ECI ต่ำ:**  
  - สะท้อนว่าสถาบันมีความเชี่ยวชาญใน **หัวข้อจำกัดหรือหัวข้อที่แพร่หลายทั่วไป**  
  - งานวิจัยมีแนวโน้มที่จะ **ไม่ซับซ้อนมากนักหรืออยู่ในระดับพื้นฐาน**  
  - *ตัวอย่าง:* มหาวิทยาลัยที่ตีพิมพ์เฉพาะในหัวข้อทั่วไป จะมีค่า ECI ต่ำกว่า  

---

## **สรุปตาราง (Summary Table)**

| ตัวชี้วัด (Metric) | ความหมาย (Meaning) |
|--------------------|--------------------|
| **ECI (สูง)** | สถาบันผลิตงานวิจัยในหัวข้อที่หลากหลายและเฉพาะทางสูง สะท้อนถึงศักยภาพการวิจัยขั้นสูง |
| **ECI (ต่ำ)** | สถาบันมุ่งเน้นในหัวข้อจำกัดหรือหัวข้อทั่วไป สะท้อนถึงความซับซ้อนของงานวิจัยที่ต่ำกว่า |


## **ตารางแสดงค่าดัชนีความซับซ้อนทางเศรษฐกิจของสถาบันวิจัย (ECI Rankings)**

| ลำดับ | สถาบัน (Institution) | ค่า ECI |
|:------:|------------------------|:-------:|
| 1 | Mahidol University | 0.745844 |
| 2 | Chulalongkorn University | 0.573940 |
| 3 | Chiang Mai University | 0.510819 |
| 4 | Silpakorn University | 0.490107 |
| 5 | King Mongkut's University of Technology Thonburi | 0.453606 |
| 6 | Suranaree University of Technology | 0.432759 |
| 7 | Walailak University | 0.430088 |
| 8 | Naresuan University | 0.346462 |
| 9 | Khon Kaen University | 0.330760 |
| 10 | Thammasat University | 0.254533 |
| 11 | Prince of Songkla University | 0.222884 |
| 12 | Kasetsart University | -0.149227 |
| 13 | Vidyasirimedhi Institute of Science and Technology | -0.498426 |
| 14 | National Institute of Development Administration | -0.881784 |
| 15 | Mahasarakham University | -3.262363 |

**หมายเหตุ : ค่าดังกล่าวมีการแปรผันตามจำนวนผลงานวิจัยบนฐานข้อมูล เนื่องจากฐาน ArXiv ไม่ใช่ฐานหลักในการดำเนินการวิจัยของมหาวิทยาลัยในไทย**

จากตาราง **ดัชนีความซับซ้อนทางเศรษฐกิจของสถาบันวิจัย (Economic Complexity Index: ECI)** ซึ่งสะท้อนถึง **ขีดความสามารถ ความหลากหลาย และความเชี่ยวชาญเชิงลึกของงานวิจัย** ของแต่ละสถาบัน พบว่า **มหาวิทยาลัยสงขลานครินทร์ (PSU)** มีค่า **ECI = 0.222884** จัดอยู่ใน **อันดับที่ 11 จาก 15 สถาบัน**  

### 🔍 **การตีความผลลัพธ์**
- ค่า ECI บ่งบอกถึง **ความซับซ้อนขององค์ความรู้และความสามารถของสถาบัน**  ซึ่งวัดจากความหลากหลายของหัวข้องานวิจัย และระดับความเฉพาะทางของแต่ละหัวข้อ  
- PSU มีค่า ECI อยู่ในระดับ **ปานกลางค่อนไปทางต่ำ** เมื่อเทียบกับมหาวิทยาลัยชั้นนำของประเทศ เช่น **Mahidol University, Chulalongkorn University, และ Chiang Mai University** ที่มีค่า ECI สูงกว่า  

### 💡 **ข้อเสนอเชิงกลยุทธ์**
1. **ขยายความเชี่ยวชาญในหัวข้อเฉพาะทาง (Niche Areas)** เพื่อสร้างความโดดเด่นในด้านที่สอดคล้องกับจุดแข็งของภาคใต้ เช่น นวัตกรรมสุขภาพและเทคโนโลยีชีวภาพ พลังงานสะอาดและความยั่งยืน เทคโนโลยีทางทะเลและสิ่งแวดล้อมชายฝั่ง  
2. **ส่งเสริมการบูรณาการสหสาขา (Interdisciplinary Research)**  เพื่อเพิ่มความซับซ้อนและคุณค่าทางวิชาการของงานวิจัย PSU  
3. **สร้างเครือข่ายความร่วมมือเชิงลึก (Research Network Expansion)** กับสถาบันที่มี ECI สูง เพื่อยกระดับคุณภาพและขีดความสามารถในการแข่งขันระดับประเทศ  


# **Product Complexity Index (Research) Analysis**
## **คำจำกัดความ (Definition)**

> **ดัชนีความซับซ้อนของหัวข้องานวิจัย (Product Complexity Index: PCI)**  
> ใช้ในการวัดระดับ **ความซับซ้อนของหัวข้องานวิจัย (Research Topic)** โดยพิจารณาจากจำนวนและความสามารถของสถาบันที่สามารถผลิตผลงานคุณภาพสูงในหัวข้อนั้น ๆ  
> แนวคิดนี้ดัดแปลงมาจากทฤษฎี **Economic Complexity** ที่ใช้วัดความซับซ้อนของสินค้าในระบบเศรษฐกิจระหว่างประเทศ

โดย PCI พิจารณาจากปัจจัยหลัก 2 ประการ:
1. **Ubiquity (การแพร่หลายของหัวข้อ):**  หัวข้อที่มีงานวิจัยจากสถาบันจำนวนน้อยถือว่ามีความซับซ้อนสูงกว่า เพราะต้องอาศัยความเชี่ยวชาญเฉพาะทาง
2. **Institution Diversity (ความหลากหลายของสถาบัน):**  หัวข้อที่ซับซ้อนมักถูกผลิตโดยสถาบันที่มีศักยภาพสูงและมีขอบเขตงานวิจัยที่หลากหลาย
กล่าวโดยสรุป หัวข้อที่มีเพียงไม่กี่สถาบันชั้นนำสามารถทำวิจัยได้ จะมีค่า **PCI สูง** ซึ่งสะท้อนถึงความก้าวหน้าทางวิชาการและความเชี่ยวชาญเฉพาะทางสูง

---

## **การตีความ (Interpretation)**

- **PCI สูง:**  
  - หัวข้อมีลักษณะ **เฉพาะทางและพบได้น้อย**  
  - มีเพียงสถาบันที่มี **ขีดความสามารถสูงและโครงสร้างการวิจัยที่ซับซ้อน** เท่านั้นที่สามารถผลิตงานในหัวข้อนี้ได้  
  - *ตัวอย่าง:* “Quantum Photonics” หรือ “Advanced Nanomaterials” มักเป็นหัวข้อที่มี PCI สูง  

- **PCI ต่ำ:**  
  - หัวข้อมีลักษณะ **ทั่วไปและแพร่หลาย**  
  - สถาบันส่วนใหญ่สามารถผลิตงานในหัวข้อนี้ได้ แสดงถึงความซับซ้อนต่ำกว่า  
  - *ตัวอย่าง:* “General Machine Learning” หรือ “Basic Algebra” มักเป็นหัวข้อที่มี PCI ต่ำ  

---

## **ตารางสรุป (Summary Table)**

| ตัวชี้วัด (Metric) | ความหมาย (Meaning) |
|----------------------|----------------------|
| **PCI (สูง)** | หัวข้อเฉพาะทาง พบได้น้อย ผลิตได้โดยสถาบันที่มีขีดความสามารถสูง |
| **PCI (ต่ำ)** | หัวข้อทั่วไป พบได้ในหลายสถาบัน แสดงถึงความซับซ้อนที่ต่ำกว่า |

## **ตารางหัวข้อที่มีความซับซ้อนสูงสุด (Highest PCI Topics)**

| No. | Research Topic | PCI |
|-----|----------------|-----|
| 1 | Semiconductor materials and devices | 0.721724 |
| 2 | Mental Health via Writing | 0.721724 |
| 3 | Microbial Natural Products and Biosynthesis | 0.721724 |
| 4 | Photorefractive and Nonlinear Optics | 0.721724 |
| 5 | Plant biochemistry and biosynthesis | 0.721724 |
| 6 | Statistical Methods and Bayesian Inference | 0.721724 |
| 7 | Quasicrystal Structures and Properties | 0.721724 |
| 8 | Rare-earth and actinide compounds | 0.721724 |
| 9 | Text Readability and Simplification | 0.721724 |
| 10 | Textile materials and evaluations | 0.721724 |

---

## **การตีความ (Interpretation)**

หัวข้อเหล่านี้เป็นตัวสะท้อนถึงความสามารถทางวิจัยในระดับสูงของสถาบันที่ทำงานในพื้นที่เหล่านี้ โดยเฉพาะในสาขาที่ต้องใช้เทคโนโลยีและความรู้เฉพาะทาง เช่น  
- **วัสดุศาสตร์ (Semiconductor, Rare-earth compounds)**  
- **วิทยาศาสตร์ชีวภาพขั้นสูง (Microbial Natural Products, Plant biochemistry)**  
- **สถิติและวิธีเชิงคำนวณ (Bayesian Inference)**  

การมีส่วนร่วมของมหาวิทยาลัยกลุ่ม 1 ในหัวข้อที่มี PCI สูงสะท้อนถึง **ความก้าวหน้าเชิงลึกและความเชี่ยวชาญเฉพาะด้านของกลุ่มมหาวิทยาลัย**

<img width="1132" height="556" alt="image" src="https://github.com/user-attachments/assets/082b046b-4f1e-47c0-a78a-0d6ce0d6a2b4" />

**ข้อมูลเชิงลึก (Insight) :** จากกราฟแสดงให้เห็น มหาวิทยาลัยที่มี ECI (Research) ที่สูงก็จะมีความสถาบันในการดำเนินงานวิจัยที่ความซับซ้อนและแสดงให้เห็นถึงความสามารถในการดำเนินงานวิจัยขั้นสูง (Deeptech) ดังนั้น มหาวิทยาลัยสงขลานครินทร์ที่ยังมี ECI ไม่สูงมาก และ PCI ที่สามารถดำเนินงานวิจัยก็ยังถือว่าต่ำ ควรเร่งพัฒนาและสร้างความร่วมมือเพื่อให้เกิดการทำงานวิจัยขั้นสูงมากยิ่งขึ้น


# Relatedness
## นิยาม (Definition)
> **Relatedness** คือค่าที่วัดว่า **หัวข้องานวิจัยมีความใกล้เคียงกับศักยภาพหรือความเชี่ยวชาญปัจจุบันของสถาบันมากน้อยเพียงใด**  
เป็นตัวชี้วัดว่า “สถาบันสามารถขยายงานวิจัยไปสู่หัวข้อใหม่ได้ง่ายแค่ไหน” โดยอิงจากความสัมพันธ์ของหัวข้อวิจัยที่มีอยู่

โดยหลักการแล้ว:
- ค่าความสัมพันธ์นี้คำนวณจาก **การเกิดร่วมกันของหัวข้อวิจัย (co-occurrence)** ระหว่างสถาบันต่าง ๆ  
- หากหัวข้อหนึ่งมักปรากฏร่วมกับหัวข้อที่สถาบันนั้นเชี่ยวชาญอยู่แล้ว จะมีค่า **Relatedness สูง**  
- ค่าจะอยู่ระหว่าง 0 ถึง 1  
  - **0 →** หัวข้อไม่เกี่ยวข้องกับศักยภาพปัจจุบัน  
  - **1 →** หัวข้อมีความสัมพันธ์สูงกับความเชี่ยวชาญเดิม

---

## การตีความ (Interpretation)

- **ค่าความสัมพันธ์สูง (High Relatedness; ใกล้ 1):**  
  - หมายถึงหัวข้อวิจัยนั้น **สอดคล้องกับความเชี่ยวชาญปัจจุบันของสถาบัน**  
  - การขยายไปยังหัวข้อนี้ทำได้ **ง่ายและมีความเป็นไปได้สูง**  
  - *ตัวอย่าง:* หากสถาบันมีงานวิจัยด้าน “Machine Learning for Healthcare”  
    หัวข้อ “AI in Cancer Detection” จะมีค่า Relatedness สูง

- **ค่าความสัมพันธ์ต่ำ (Low Relatedness; ใกล้ 0):**  
  - หมายถึงหัวข้อวิจัยนั้น **ห่างไกลจากความเชี่ยวชาญของสถาบัน**  
  - การขยายไปสู่หัวข้อนี้อาจ **ยากและต้องการศักยภาพหรือพันธมิตรใหม่**  
  - *ตัวอย่าง:* สถาบันที่เน้น “Plant Biochemistry” จะมีค่า Relatedness ต่ำกับ “Quantum Computing”

---

## สรุปความหมาย (Summary Table)

| Metric              | ความหมาย                                                                    |
|--------------------|----------------------------------------------------------------------------|
| **High Relatedness** | หัวข้อมีความใกล้เคียงกับความเชี่ยวชาญของสถาบัน ขยายต่อได้ง่าย |
| **Low Relatedness**  | หัวข้อห่างจากความเชี่ยวชาญของสถาบัน ต้องใช้ทรัพยากรหรือความร่วมมือเพิ่มเติม |


## Relatedness (Prince of Songkla University)

ตารางนี้แสดงหัวข้อวิจัยที่มี **ความสัมพันธ์ (Relatedness)** สูงกับศักยภาพการวิจัยปัจจุบันของมหาวิทยาลัยสงขลานครินทร์ (PSU)  
หัวข้อที่มีค่า Relatedness ใกล้ **1.0** หมายถึงหัวข้อที่สถาบันมีความเชี่ยวชาญอยู่แล้ว หรือสามารถขยายงานวิจัยได้ง่าย  
ในขณะที่ค่าต่ำกว่า 1 แสดงถึงหัวข้อที่ต้องการการพัฒนาเพิ่มเติมหรือความร่วมมือจากภายนอก

---

| ลำดับ | หัวข้อวิจัย (Topic) | Relatedness |
|-------:|----------------------|-------------:|
| 1 | Retinal Imaging and Analysis | 1.000000 |
| 2 | Retinal Diseases and Treatments | 1.000000 |
| 3 | Service-Oriented Architecture and Web Services | 1.000000 |
| 4 | Real-Time Systems Scheduling | 1.000000 |
| 5 | Security and Verification in Computing | 1.000000 |
| 6 | Advanced Chemical Sensor Technologies | 1.000000 |
| 7 | Physical Unclonable Functions (PUFs) and Hardware Security | 1.000000 |
| 8 | Advanced Data Storage Technologies | 1.000000 |
| 9 | Advanced Malware Detection Techniques | 1.000000 |
| 10 | Spectroscopy Techniques in Biomedical and Chemical Analysis | 1.000000 |
| 11 | Spectroscopy and Chemometric Analyses | 1.000000 |
| 12 | Distributed Systems and Fault Tolerance | 1.000000 |
| 13 | Green IT and Sustainability | 1.000000 |
| 14 | Advanced Numerical Analysis Techniques | 0.665521 |
| 15 | Caching and Content Delivery | 0.560318 |
| 16 | Mobile Agent-Based Network Management | 0.560318 |

---

### 🔍 สรุปเชิงกลยุทธ์
- หัวข้อที่มีค่า **Relatedness = 1.0** ควรถูกระบุเป็น “**Core Research Strengths**” ของ PSU  
  เช่น *Retinal Imaging*, *Advanced Sensor Technologies*, และ *Green IT*.  
- หัวข้อที่มีค่า **Relatedness 0.5–0.7** ควรถูกมองว่าเป็น “**Emerging Opportunities**”  
  ซึ่งสามารถต่อยอดได้หากได้รับการสนับสนุนด้านบุคลากรและความร่วมมือวิจัยเพิ่มเติม


### โจทย์วิเคราะห์ที่ 3 : วิเคราะห์เบื้องต้นเกี่ยวกับเครือข่ายผู้เขียนร่วม (Co-authorship) เพื่อดูรูปแบบความร่วมมือภายในและระหว่างสถาบัน
1. ทางผู้สอบได้ดำเนินการเตรียมข้อมูลจากการดึง OpenAlex API เกี่ยวกับลักษณะของหน่วยงานหรือองค์กรที่สังกัด และ สร้างออกมาเป็นรูปแบบความร่วมมือ 2 แบบคือ ความร่วมมือโดย Sector และความร่วมมือ Geological จึงนำมาวิเคราะห์รูปแบบความร่วมได้ดังภาพ
<img width="1077" height="563" alt="image" src="https://github.com/user-attachments/assets/7e7742d7-a0ad-4539-a7ac-b06f07405ce2" />


**ข้อมูลเชิงลึก (Insight) :** จากกราฟแสดงให้เห็นมหาวิทยาลัยส่วนใหญ่ก็จะเป็นรูปแบบความร่วมมือแบบนานาชาติเป็นหลัก แต่ก็ยังอยู่ในรูปแบบความร่วมมือเชิงวิชาการ ยังมีความร่วมมือเชิงธุรกิจน้อย ดังนั้น เราควรพยายามที่จะทำงานวิจัยร่วมกับเอกชนเพื่อสร้างให้เกิดการทำงานที่หลากหลายและเพิ่มโอกาสให้งานวิจัยได้ถูกนำไปประยุกต์ใช้ในภาคอุตสาหกรรมในอนาคตมากขึ้น


###  2. การพัฒนาแบบจำลอง (Model) เพื่อทำนาย "ศักยภาพในการสร้างผลกระทบของบทความวิจัย"

### Target Variable Definition

**Target Variable:** `high_impact_paper` (บทความที่มีผลกระทบสูง)

## Definition

> บทความที่มีผลกระทบสูง คือบทความที่ **อยู่ใน 10% แรกของการอ้างอิงแบบ Comprehensive ในสาขาและปีที่ตีพิมพ์เดียวกัน**  
> *(Comprehensive citations คือการรวมผลกระทบตั้งต้นจากปีแรก, ผลกระทบล่าสุด 3 ปี, และค่าเฉลี่ยการอ้างอิงสะสมต่อปี)*

**สูตรคำนวณ Impact Score:**

$$
\text{Impact Score}_{paper} = \text{1st-year citation} + \text{Recent 3-year citation} + \frac{\text{Total citations}}{\text{อายุการตีพิมพ์ (ปี)}}
$$

**เงื่อนไขบทความที่มีผลกระทบสูง:**

$$
\text{Impact Score}_{paper} \geq \text{Percentile}_{90} \big( \text{Impact Score} \big)_{field, year}
$$


## Rationale

1. **Comprehensive Citation Metric:**  
   - รวมทั้ง **ผลกระทบตั้งต้น** (การอ้างอิงปีแรก), **ผลกระทบล่าสุด** (การอ้างอิง 3 ปีล่าสุด), และ **ผลกระทบโดยรวม** (ค่าเฉลี่ยการอ้างอิงสะสมต่อปี) เพื่อสะท้อนอิทธิพลที่แท้จริงของบทความ  

2. **Field- and Year-Normalization:**  
   - การคำนวณ percentile **ภายในสาขาและปีที่ตีพิมพ์เดียวกัน** ลดความเบี่ยงเบนจากความแตกต่างของพฤติกรรมการอ้างอิงในแต่ละสาขาและปี  

3. **Top 10% Standard:**  
   - การใช้เกณฑ์ **10% แรก** เป็นวิธีมาตรฐานใน bibliometrics เพื่อระบุบทความวิจัยที่มีผลกระทบสูง

### โจทย์วิเคราะห์ที่ 1 : สร้างแบบจำลองพื้นฐาน (Baseline Model) จากข้อมูลที่ได้จาก Metadata ทั่วไป
# **Building the Baseline Model** 
## Summary Feature

| Feature                | Meaning                                                                 |
|-----------------------|-------------------------------------------------------------------------|
| **Number of Authors** | จำนวนผู้แต่งที่มีส่วนร่วมในบทความ                                         |
| **Abstract Length**   | ความยาวของบทคัดย่อของบทความ                                            |
| **Field/Discipline**  | หมวดหมู่หรือสาขาของงานวิจัย                                            |
| **Affiliated University** | มหาวิทยาลัยหรือสถาบันที่ผู้แต่งสังกัด                                 |

โดยแบบจำลองที่ใช้ในการพัฒนาคือ Logistic Regression

# Baseline Model Performance Summary (Cross-validation 10 Folds)

| Metric    | Mean    | Std     |
|-----------|--------|--------|
| Accuracy  | 0.8312 | 0.0044 |
| AUC       | 0.7133 | 0.0183 |
| Recall    | 0.2080 | 0.0235 |
| Precision | 0.6443 | 0.0327 |
| F1        | 0.3140 | 0.0288 |
| Kappa     | 0.2457 | 0.0275 |
| MCC       | 0.2974 | 0.0270 |

**แปลผลแบบจำลอง**
Accuracy (83.1%): แบบจำลองสามารถทำนายถูกต้องโดยรวมได้สูง แต่ Accuracy อาจหลอกได้ เพราะ class imbalance (High-impact papers มีจำนวนน้อยกว่า Normal papers)
AUC (71.3%): แบบจำลองมีความสามารถแยกระหว่าง High-impact กับ Normal paper อยู่ในระดับปานกลาง
Recall (20.8%): แบบจำลองมีโอกาสพลาดในการทำนายผลงานที่มีผลกระทบสูง
Precision (64.4%): เมื่อแบบจำลองทำนายว่าเป็น High-impact paper ส่วนใหญ่ถูกต้อง
F1 (31.4%): แบบจำลองยังขาดความสมดุลระหว่างความแม่นยำ และความครอบคลุมของการทำนายที่ถูกต้อง (เน้น Precision มากกว่า Recall)
Kappa / MCC (~0.25-0.30): โมเดลมี performance เกิน random แต่ยังไม่ได้ดีมาก
โดยสรุป แบบจำลอง baseline (Logistic Regression) สามารถทำหน้าที่เป็น benchmark ได้ดี แต่ยังต้องปรับปรุง Recall เพื่อให้สามารถจับ High-impact papers ได้มากขึ้น

### โจทย์วิเคราะห์ที่ 2 : สร้างแบบจำลองจากข้อมูลที่ได้จาก Metadata ทั่วไป + Feature Engineering (TF-IDF)

## Summary Feature

| Feature                | Meaning                                                                 |
|-----------------------|-------------------------------------------------------------------------|
| **Number of Authors** | จำนวนผู้แต่งที่มีส่วนร่วมในบทความ                                         |
| **Abstract Length**   | ความยาวของบทคัดย่อของบทความ                                            |
| **Field/Discipline**  | หมวดหมู่หรือสาขาของงานวิจัย                                            |
| **Affiliated University** | มหาวิทยาลัยหรือสถาบันที่ผู้แต่งสังกัด                                 |
| **TF-IDF Abstract**   | การสร้าง Vector ของคำสำหรับสกัดข้อมูลจากบทคัดย่อ |

# Model Performance Comparison

| Model       | Accuracy | AUC    | Recall  | Precision | F1     | Kappa  | MCC    | TT (Sec) |
|------------|---------|--------|--------|----------|--------|-------|-------|----------|
| XGBoost    | 0.9325  | 0.9590 | 0.6799 | 0.9414   | 0.7894 | 0.7505 | 0.7647 | 0.5510  |
| Decision Tree | 0.9051 | 0.8507 | 0.7422 | 0.7473   | 0.7445 | 0.6863 | 0.6865 | 0.3720  |
| Logistic Regression | 0.8404 | 0.7512 | 0.2649 | 0.6851 | 0.3816 | 0.3101 | 0.3567 | 1.8580 |

**การเพิ่ม Textual Feature จากกระบวนการ TF-IDF รวมกับแบบจำลองที่มีความซับซ้อนเพิ่มมากขึ้น ทำให้การทำนายผลของแบบจำลองดีขึ้นอย่างชัดเจน**
สรุปการประเมิน
XGBoost เป็นโมเดลที่เหมาะสมที่สุด สำหรับการคัดเลือก High-impact papers ด้วยความแม่นยำและสมดุลระหว่าง Recall และ Precision
Decision Tree ยังสามารถใช้ได้แต่ประสิทธิภาพต่ำกว่า XGBoost
Logistic Regression ใช้เป็น baseline เท่านั้น

## เหตุผลในการเลือกและใช้โมเดลที่มีประสิทธิภาพสูง

### 1. การเปรียบเทียบกับ Baseline
- **Baseline Model:** Logistic Regression  
  - ใช้ง่ายและ interpretability สูง  
  - Performance: Accuracy 84%, AUC 75%, Recall 26%, F1 0.38  
  - **ข้อจำกัด:** ไม่สามารถจับ High-impact papers ได้ดี (Recall ต่ำ) ทำให้พลาดงานวิจัยสำคัญ  

- **โมเดลประสิทธิภาพสูง:** XGBoost  
  - Performance: Accuracy 93%, AUC 96%, Recall 68%, F1 0.79  
  - **เหตุผลที่เลือก:**  
    - Accuracy และ AUC สูง ทำให้สามารถแยก High-impact vs Normal papers ได้ชัดเจน  
    - Recall สูงขึ้นมากทำให้สามารถระบุ High-impact papers ได้ดีมากยิ่งขึ้น
    - F1 มีความสมดุลระหว่าง Precision และ Recall ดี  
    - Kappa/MCC สูง โมเดลเสถียรและมี performance เกิน random chance อย่างชัดเจน  
    - Time-to-train ต่ำ → ใช้งานได้จริง
    - การใช้ XGBoost เนื่องจากเป็นแบบจำลองที่มีประสิทธิภาพที่สูงขึ้นมากเมื่อเทียบกับ Logistic แต่ยังถือว่าเป็นแบบจำลองที่มีความสามารถในการอธิบายและแปลผลได้อยู่ในระดับที่ดี (Explainable Level) เมื่อเทียบกับแบบจำลองการเรียนรู้เชิงลึกที่ระดับความสามารถในการอธิบายที่มาของการตัดสินใจที่ต่ำกว่ามาก

### 2. เหตุผลทางกลยุทธ์
- การเลือกโมเดลที่มี **ประสิทธิภาพสูงกว่า baseline** ทำให้:
  - สามารถ **ระบุผลงานวิจัยสำคัญ** ได้แม่นยำกว่า  
  - ช่วย **วิเคราะห์แนวโน้มและคุณภาพของงานวิจัย** ในมหาวิทยาลัย  
  - ลดความเสี่ยงจากการพลาด High-impact papers ที่สำคัญต่อการวางแผนงานวิจัยหรือจัดสรรทรัพยากร  

### โจทย์วิเคราะห์ที่ 3 : สร้างแบบจำลองจากข้อมูลที่ได้จาก Metadata ทั่วไป + แบบจำลองขั้นสูงด้วย SciBERT
- เนื่องจากเวลาที่จำกัดทางผู้สอบเลยเลือกใช้ Model ดังกล่าวในการสร้าง Textual Feature โดยการนำมาสร้าง Embedding ของคำที่ได้จากบทคัดย่อโดยการใช้ `allenai/scibert_scivocab_cased`
## Summary Feature

| Feature                | Meaning                                                                 |
|-----------------------|-------------------------------------------------------------------------|
| **Number of Authors** | จำนวนผู้แต่งที่มีส่วนร่วมในบทความ                                         |
| **Abstract Length**   | ความยาวของบทคัดย่อของบทความ                                            |
| **Field/Discipline**  | หมวดหมู่หรือสาขาของงานวิจัย                                            |
| **Affiliated University** | มหาวิทยาลัยหรือสถาบันที่ผู้แต่งสังกัด                                 |
| **Embedding Abstract**   | การสร้าง Embedding ของคำสำหรับสกัดข้อมูลจากบทคัดย่อ |

| Model      | Accuracy | AUC    | Recall | Precision | F1     | Kappa  | MCC    | TT (Sec) | Notes |
|------------|---------|--------|--------|-----------|--------|--------|--------|----------|-------|
| **XGBoost** (Extreme Gradient Boosting) | **0.9776** | **0.9861** | **0.9047** | **0.9731** | **0.9376** | **0.9240** | **0.9249** | 13.15   | **Best overall performance** |
| Decision Tree Classifier | 0.9156  | 0.8730 | 0.7898 | 0.7646    | 0.7769 | 0.7249 | 0.7251 | 33.32   | Easier to interpret, moderate performance |
| Logistic Regression      | 0.8715  | 0.8378 | 0.4537 | 0.7608    | 0.5676 | 0.4979 | 0.5213 | 12.81   | Baseline model, lower recall |

## สรุปผลเปรียบเทียบโมเดล

จากผลลัพธ์โมเดลทั้ง 3 ตัว พบว่า:
### XGBoost (Extreme Gradient Boosting)
- มี **ประสิทธิภาพสูงสุดทุกด้าน:**  
  - Accuracy: 0.978  
  - AUC: 0.986  
  - Recall: 0.905  
  - Precision: 0.973  
  - F1: 0.938  
  - Kappa: 0.924  
  - MCC: 0.925
- **เวลาในการประมวลผล:** 13.15 วินาที ถือว่ารับได้เมื่อเทียบกับความแม่นยำ
- **ข้อดี:** เหมาะสำหรับใช้เป็นโมเดลหลักในการทำนาย “High-Impact Paper” เนื่องจากทั้ง Recall และ Precision สูง หมายถึงสามารถจับ paper ที่มีผลกระทบสูงได้อย่างแม่นยำ

### Decision Tree Classifier
- **ประสิทธิภาพรองลงมา:**  
  - Accuracy: 0.916  
  - AUC: 0.873  
  - Recall: 0.790  
  - F1: 0.777
- **เวลาในการประมวลผล:** 33.32 วินาที
- **ข้อดี:** เข้าใจง่าย ตีความผลลัพธ์ได้ชัดเจน แต่ความแม่นยำและความสมดุลของโมเดลยังต่ำกว่า XGBoost

### Logistic Regression
- เป็น **baseline model:**  
  - Accuracy: 0.872  
  - AUC: 0.838  
  - Recall: 0.454  
  - F1: 0.568
- **เวลาในการประมวลผล:** 12.81 วินาที
- **ข้อดี:** ความแม่นยำต่ำที่สุดโดยเฉพาะ Recall หมายถึงจับ paper ที่มีผลกระทบสูงได้น้อย  
  เหมาะสำหรับ baseline comparison หรือการทดสอบเบื้องต้น

### สรุป
- **XGBoost** เป็นโมเดลที่เหมาะสมที่สุดสำหรับการทำนาย High-Impact Paper เนื่องจากสามารถจับกลุ่มเป้าหมายได้แม่นยำและสมดุลระหว่าง Precision กับ Recall
- **Logistic Regression** เหมาะสำหรับ baseline comparison หรือการทดสอบเบื้องต้น
- **Decision Tree** มีประโยชน์ด้านความเข้าใจง่าย แต่ไม่เหมาะเป็นโมเดลหลักหากต้องการผลลัพธ์แม่นยำสูง




